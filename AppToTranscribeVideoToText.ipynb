{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWdp0s42b99sFL0lZEh7q6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unimama/learning/blob/master/AppToTranscribeVideoToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üéôÔ∏è TRANSCRI√á√ÉO AUTOM√ÅTICA COM WHISPER\n",
        "# Execute cada bloco separadamente no Google Colab\n",
        "# =============================================================================\n",
        "\n",
        "# BLOCO 1: Verificar ambiente\n",
        "import sys, platform\n",
        "print(\"üêç Python:\", sys.version)\n",
        "print(\"üíª Plataforma:\", platform.platform())\n",
        "print(\"\\n‚úÖ Ambiente pronto para come√ßar!\")\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCO 2: Instala√ß√£o (Execute uma vez)\n",
        "print(\"üîß Instalando depend√™ncias...\")\n",
        "!pip -q install git+https://github.com/openai/whisper.git\n",
        "!pip -q install torch --index-url https://download.pytorch.org/whl/cu118\n",
        "!apt -q update && apt -q install -y ffmpeg\n",
        "print(\"‚úÖ Instala√ß√£o conclu√≠da!\")\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCO 3: Upload do arquivo\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üì§ Clique no bot√£o abaixo para enviar seu arquivo:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Pega o primeiro arquivo enviado\n",
        "input_path = list(uploaded.keys())[0]\n",
        "file_size_mb = os.path.getsize(input_path) / 1e6\n",
        "\n",
        "print(f\"\\n‚úÖ Arquivo recebido: {input_path}\")\n",
        "print(f\"üìä Tamanho: {file_size_mb:.2f} MB\")\n",
        "print(f\"üéØ Pronto para transcrever!\")\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCO 4: Transcri√ß√£o principal\n",
        "import whisper\n",
        "import re\n",
        "\n",
        "print(\"ü§ñ Carregando modelo Whisper...\")\n",
        "# Modelos: tiny, base, small, medium, large\n",
        "MODEL_NAME = \"medium\"  # Mude para \"small\" se quiser mais r√°pido\n",
        "model = whisper.load_model(MODEL_NAME)\n",
        "print(f\"‚úÖ Modelo '{MODEL_NAME}' carregado!\")\n",
        "\n",
        "print(\"\\nüéôÔ∏è Iniciando transcri√ß√£o...\")\n",
        "result = model.transcribe(input_path, language=\"pt\", verbose=False)\n",
        "print(\"‚úÖ Transcri√ß√£o conclu√≠da!\")\n",
        "\n",
        "def formato_tempo(seconds: float) -> str:\n",
        "    \"\"\"Converte segundos para formato hh:mm:ss\"\"\"\n",
        "    seconds = max(0, float(seconds))\n",
        "    h = int(seconds // 3600)\n",
        "    m = int((seconds % 3600) // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# Processar segmentos e quebrar em frases\n",
        "frases_com_tempo = []\n",
        "for segmento in result.get(\"segments\", []):\n",
        "    tempo_inicio = formato_tempo(segmento[\"start\"])\n",
        "    texto = segmento[\"text\"].strip()\n",
        "\n",
        "    # Quebrar por frases usando pontua√ß√£o\n",
        "    frases = re.split(r'(?<=[.!?])\\s+', texto)\n",
        "\n",
        "    for frase in frases:\n",
        "        frase = frase.strip()\n",
        "        if frase:\n",
        "            frases_com_tempo.append((tempo_inicio, frase))\n",
        "\n",
        "print(f\"\\nüìù Total de frases processadas: {len(frases_com_tempo)}\")\n",
        "print(\"\\nüîç Primeiras 5 frases:\")\n",
        "for i, (tempo, frase) in enumerate(frases_com_tempo[:5]):\n",
        "    print(f\"[{tempo}] {frase}\")\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCO 5: Adicionar nomes dos falantes\n",
        "# CONFIGURE AQUI OS NOMES DOS SEUS FALANTES:\n",
        "FALANTE_1 = \"Entrevistador\"  # Mude aqui\n",
        "FALANTE_2 = \"Entrevistado\"   # Mude aqui\n",
        "\n",
        "# Estrat√©gia simples: alternar falantes\n",
        "linhas_finais = []\n",
        "for i, (tempo, frase) in enumerate(frases_com_tempo):\n",
        "    # Alterna entre falantes (come√ßando com FALANTE_1)\n",
        "    falante = FALANTE_1 if i % 2 == 0 else FALANTE_2\n",
        "    linha = f\"[{tempo}] {falante}: {frase}\"\n",
        "    linhas_finais.append(linha)\n",
        "\n",
        "print(f\"‚úÖ Formata√ß√£o conclu√≠da com {len(linhas_finais)} linhas\")\n",
        "print(\"\\nüìã Exemplo do resultado:\")\n",
        "for linha in linhas_finais[:8]:\n",
        "    print(linha)\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCO 6: Exportar e baixar arquivos\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# Nome base para os arquivos\n",
        "nome_base = input_path.split('.')[0]\n",
        "\n",
        "# === ARQUIVO TXT ===\n",
        "arquivo_txt = f\"{nome_base}_transcricao.txt\"\n",
        "conteudo_txt = \"\\n\".join(linhas_finais)\n",
        "\n",
        "with open(arquivo_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(conteudo_txt)\n",
        "\n",
        "print(f\"‚úÖ Arquivo TXT criado: {arquivo_txt}\")\n",
        "\n",
        "# === ARQUIVO SRT ===\n",
        "def parse_linha(linha):\n",
        "    \"\"\"Extrai tempo, falante e texto de uma linha\"\"\"\n",
        "    match = re.match(r\"\\[(\\d{2}:\\d{2}:\\d{2})\\]\\s([^:]+):\\s(.+)\", linha)\n",
        "    if not match:\n",
        "        return None\n",
        "    tempo_str, falante, texto = match.groups()\n",
        "    h, m, s = map(int, tempo_str.split(\":\"))\n",
        "    tempo_segundos = h*3600 + m*60 + s\n",
        "    return tempo_segundos, falante, texto\n",
        "\n",
        "def formato_srt(segundos):\n",
        "    \"\"\"Converte segundos para formato SRT (hh:mm:ss,mmm)\"\"\"\n",
        "    h = int(segundos // 3600)\n",
        "    m = int((segundos % 3600) // 60)\n",
        "    s = int(segundos % 60)\n",
        "    ms = int((segundos - int(segundos)) * 1000)\n",
        "    return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
        "\n",
        "# Processar linhas para SRT\n",
        "entradas_srt = []\n",
        "for linha in linhas_finais:\n",
        "    dados = parse_linha(linha)\n",
        "    if dados:\n",
        "        entradas_srt.append(dados)\n",
        "\n",
        "# Gerar arquivo SRT\n",
        "arquivo_srt = f\"{nome_base}_transcricao.srt\"\n",
        "linhas_srt = []\n",
        "DURACAO_FRASE = 3.0  # segundos por frase\n",
        "\n",
        "for idx, (inicio, falante, texto) in enumerate(entradas_srt, 1):\n",
        "    fim = inicio + DURACAO_FRASE\n",
        "    linhas_srt.append(str(idx))\n",
        "    linhas_srt.append(f\"{formato_srt(inicio)} --> {formato_srt(fim)}\")\n",
        "    linhas_srt.append(f\"{falante}: {texto}\")\n",
        "    linhas_srt.append(\"\")\n",
        "\n",
        "with open(arquivo_srt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(linhas_srt))\n",
        "\n",
        "print(f\"‚úÖ Arquivo SRT criado: {arquivo_srt}\")\n",
        "\n",
        "# === DOWNLOAD DOS ARQUIVOS ===\n",
        "print(\"\\nüì• Fazendo download dos arquivos...\")\n",
        "files.download(arquivo_txt)\n",
        "files.download(arquivo_srt)\n",
        "\n",
        "print(\"\\nüéâ Transcri√ß√£o conclu√≠da com sucesso!\")\n",
        "print(f\"üìÑ Arquivo TXT: {arquivo_txt}\")\n",
        "print(f\"üé¨ Arquivo SRT: {arquivo_srt}\")\n",
        "\n",
        "# =============================================================================\n",
        "# üìã RESULTADO FINAL\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìã RESULTADO FINAL DA TRANSCRI√á√ÉO:\")\n",
        "print(\"=\"*50)\n",
        "for i, linha in enumerate(linhas_finais[:10]):\n",
        "    print(linha)\n",
        "if len(linhas_finais) > 10:\n",
        "    print(f\"... e mais {len(linhas_finais)-10} linhas\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_45gA2I-Eeum",
        "outputId": "53c9b7b8-7183-4c68-8916-22e1038cb985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üêç Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "üíª Plataforma: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "\n",
            "‚úÖ Ambiente pronto para come√ßar!\n",
            "üîß Instalando depend√™ncias...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,933 kB]\n",
            "Get:4 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,209 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,271 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,521 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 12.0 MB in 4s (3,129 kB/s)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "‚úÖ Instala√ß√£o conclu√≠da!\n",
            "üì§ Clique no bot√£o abaixo para enviar seu arquivo:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9899dc1e-054e-48c0-85be-ae110ca4e094\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9899dc1e-054e-48c0-85be-ae110ca4e094\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05.02.mp4 to N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05.02.mp4\n",
            "\n",
            "‚úÖ Arquivo recebido: N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05.02.mp4\n",
            "üìä Tamanho: 51.48 MB\n",
            "üéØ Pronto para transcrever!\n",
            "ü§ñ Carregando modelo Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:17<00:00, 86.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo 'medium' carregado!\n",
            "\n",
            "üéôÔ∏è Iniciando transcri√ß√£o...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63739/63739 [25:22<00:00, 41.87frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Transcri√ß√£o conclu√≠da!\n",
            "\n",
            "üìù Total de frases processadas: 221\n",
            "\n",
            "üîç Primeiras 5 frases:\n",
            "[00:00:00] Voc√™ √© daqueles ingleses que s√£o fan√°ticos pela realeza do seu pa√≠s ou n√£o?\n",
            "[00:00:05] Voc√™ curte a fam√≠lia real?\n",
            "[00:00:07] Mais ou menos.\n",
            "[00:00:08] Por qu√™?\n",
            "[00:00:09] N√£o, porque n√£o tinha nada a ver com a fam√≠lia real, n√£o.\n",
            "‚úÖ Formata√ß√£o conclu√≠da com 221 linhas\n",
            "\n",
            "üìã Exemplo do resultado:\n",
            "[00:00:00] Entrevistador: Voc√™ √© daqueles ingleses que s√£o fan√°ticos pela realeza do seu pa√≠s ou n√£o?\n",
            "[00:00:05] Entrevistado: Voc√™ curte a fam√≠lia real?\n",
            "[00:00:07] Entrevistador: Mais ou menos.\n",
            "[00:00:08] Entrevistado: Por qu√™?\n",
            "[00:00:09] Entrevistador: N√£o, porque n√£o tinha nada a ver com a fam√≠lia real, n√£o.\n",
            "[00:00:13] Entrevistado: Sim, mas no geral o povo n√£o tem, admira, acha o m√°ximo, acompanha os casamentos, torce,\n",
            "[00:00:18] Entrevistador: l√™ as not√≠cias, voc√™...\n",
            "[00:00:19] Entrevistado: N√£o, nunca foi assim, n√£o.\n",
            "‚úÖ Arquivo TXT criado: N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.txt\n",
            "‚úÖ Arquivo SRT criado: N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.srt\n",
            "\n",
            "üì• Fazendo download dos arquivos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ddeb6897-215a-4e08-bf3e-3058146a7620\", \"N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.txt\", 15054)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3a10dea-6cf5-4b2c-a4d6-5ee9fc215016\", \"N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.srt\", 20250)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ Transcri√ß√£o conclu√≠da com sucesso!\n",
            "üìÑ Arquivo TXT: N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.txt\n",
            "üé¨ Arquivo SRT: N005 - 50087151 - ARQUIVO ENTRETENIMENTO - MARILIA GABRIELA - 05_transcricao.srt\n",
            "\n",
            "==================================================\n",
            "üìã RESULTADO FINAL DA TRANSCRI√á√ÉO:\n",
            "==================================================\n",
            "[00:00:00] Entrevistador: Voc√™ √© daqueles ingleses que s√£o fan√°ticos pela realeza do seu pa√≠s ou n√£o?\n",
            "[00:00:05] Entrevistado: Voc√™ curte a fam√≠lia real?\n",
            "[00:00:07] Entrevistador: Mais ou menos.\n",
            "[00:00:08] Entrevistado: Por qu√™?\n",
            "[00:00:09] Entrevistador: N√£o, porque n√£o tinha nada a ver com a fam√≠lia real, n√£o.\n",
            "[00:00:13] Entrevistado: Sim, mas no geral o povo n√£o tem, admira, acha o m√°ximo, acompanha os casamentos, torce,\n",
            "[00:00:18] Entrevistador: l√™ as not√≠cias, voc√™...\n",
            "[00:00:19] Entrevistado: N√£o, nunca foi assim, n√£o.\n",
            "[00:00:22] Entrevistador: Mas voc√™ acha razo√°vel ter uma fam√≠lia que √© a aula atual?\n",
            "[00:00:26] Entrevistado: Acho uma coisa legal, n√£o.\n",
            "... e mais 211 linhas\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}